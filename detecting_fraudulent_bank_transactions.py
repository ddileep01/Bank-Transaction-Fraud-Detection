# -*- coding: utf-8 -*-
"""Detecting fraudulent bank transactions

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hxrdnkvZzRNCAlt3pO00G-qOIxIp93j1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 1. Business Understanding
print("Business Understanding: Detecting fraudulent bank transactions to minimize financial risk.")

# 2. Data Acquisition
print("Loading Dataset...")
path = kagglehub.dataset_download("marusagar/bank-transaction-fraud-detection")

# Constructing the correct file path
dataset_path = os.path.join(path, "Bank_Transaction_Fraud_Detection.csv")  # Ensure this matches the actual file name

df = pd.read_csv(dataset_path)  # Now reading into df
print("Dataset Loaded Successfully!")

# Display basic info about the dataset
print("Dataset Overview:")
print(df.info())
print(df.head())

# Checking for missing values
print("Missing Values:")
print(df.isnull().sum())

# Checking for duplicates
df.drop_duplicates(inplace=True)

# 3. Exploratory Data Analysis (EDA)
print("Column Names:", df.columns)  # Check available columns
if 'is_fraud' in df.columns:
    plt.figure(figsize=(6,4))
    sns.countplot(x='is_fraud', data=df)
    plt.title("Fraudulent vs. Legitimate Transactions")
    plt.show()
else:
    print("Column 'is_fraud' not found. Please check dataset column names.")

# Display statistics
print("Dataset Description:")
print(df.describe())

# Feature Selection & Preprocessing
if 'is_fraud' in df.columns:
    X = df.drop(columns=['is_fraud'])  # Features
    y = df['is_fraud']  # Target variable

    # Encoding categorical variables (if any exist)
    X = pd.get_dummies(X, drop_first=True)

    # Splitting Data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardizing the data
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # 4. Model Training & Evaluation
    models = {"Logistic Regression": LogisticRegression(), "Random Forest": RandomForestClassifier()}

    for name, model in models.items():
        print(f"Training {name}...")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        print(f"{name} Accuracy: {accuracy_score(y_test, y_pred)}")
        print(classification_report(y_test, y_pred))
        print("Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        print("-"*50)
else:
    print("Skipping model training as 'is_fraud' column is missing.")

# 5. Conclusion
print("The models have been trained and evaluated successfully. Random Forest generally performs better for fraud detection tasks due to its ability to handle imbalanced datasets and complex relationships.")